{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRbBZGUpFK6Wr8MJAdCVYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travislatchman/TheHearts/blob/main/HeartSoundClassifier_CNN_1D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0aMnZJYWXIw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from scipy.signal import butter, lfilter\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the CNN model\n",
        "# class HeartSoundClassifier(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(HeartSoundClassifier, self).__init__()\n",
        "#         self.conv1 = nn.Conv1d(1, 32, kernel_size=5)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.maxpool = nn.MaxPool1d(2)\n",
        "#         self.conv2 = nn.Conv1d(32, 64, kernel_size=5)\n",
        "#         self.flatten = nn.Flatten()\n",
        "#         self.fc1 = nn.Linear(64 * ((X_train.shape[1] - 4) // 2 - 4) // 2, 128)\n",
        "#         self.dropout = nn.Dropout(0.5)\n",
        "#         self.fc2 = nn.Linear(128, 4)  # Assuming 4 classes\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.maxpool(self.relu(self.conv1(x)))\n",
        "#         x = self.maxpool(self.relu(self.conv2(x)))\n",
        "#         x = self.flatten(x)\n",
        "#         x = self.relu(self.fc1(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n"
      ],
      "metadata": {
        "id": "AwJGhLxvWn1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Instantiate the model\n",
        "# model = HeartSoundClassifier()\n",
        "\n",
        "# # Set device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)\n",
        "# X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "# # Define loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "rhdlfT9PXGpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train the model\n",
        "# num_epochs = 20\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     model.train()\n",
        "#     for inputs, targets in train_loader:\n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, targets)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     # Validate the model\n",
        "#     model.eval()\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, targets in val_loader:\n",
        "#             inputs, targets = inputs.to(device), targets.to(device)\n",
        "#             outputs = model(inputs)\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             total += targets.size(0)\n",
        "#             correct += (predicted == targets).sum().item()\n",
        "\n",
        "#     print(f'Epoch [{epoch+1}/{num_epochs}], Validation accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "qOQgLhtsXQRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Final evaluation\n",
        "# model.eval()\n",
        "# correct = 0\n",
        "# total = 0\n",
        "# with torch.no_grad():\n",
        "#     for inputs, targets in val_loader:\n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "#         outputs = model(inputs)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += targets.size(0)\n",
        "#         correct += (predicted == targets).sum().item()\n",
        "\n",
        "# print(f'Final validation accuracy: {100 * correct / total:.2f}%')\n"
      ],
      "metadata": {
        "id": "vi7S0JCgXceb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing functions"
      ],
      "metadata": {
        "id": "7kycKlr4xKbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing functions\n",
        "def load_audio_file(file_path):\n",
        "    audio_data, sample_rate = librosa.load(file_path, sr=None)\n",
        "    return audio_data, sample_rate"
      ],
      "metadata": {
        "id": "-ZvEYAZyxHwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a"
      ],
      "metadata": {
        "id": "qd8pDBNwxRWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "metadata": {
        "id": "vUT1hc-yxTPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_lowpass_filter(audio_data, sample_rate, cutoff=195):\n",
        "    filtered_data = butter_lowpass_filter(audio_data, cutoff, sample_rate)\n",
        "    return filtered_data"
      ],
      "metadata": {
        "id": "TpyPLUJGxVEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_fft(filtered_data):\n",
        "    fft_data = np.fft.fft(filtered_data)\n",
        "    return fft_data"
      ],
      "metadata": {
        "id": "E1PwiHTXxXc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Dataset"
      ],
      "metadata": {
        "id": "kl87moFrx4lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HeartSoundDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels=None, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        audio_data, sample_rate = load_audio_file(file_path)\n",
        "        filtered_data = apply_lowpass_filter(audio_data, sample_rate)\n",
        "        fft_data = perform_fft(filtered_data)\n",
        "\n",
        "        # Use only the real part of the FFT data\n",
        "        real_fft_data = np.real(fft_data)\n",
        "\n",
        "        # Normalize data\n",
        "        normalized_data = (real_fft_data - np.min(real_fft_data)) / (np.max(real_fft_data) - np.min(real_fft_data))\n",
        "\n",
        "        if self.transform:\n",
        "            normalized_data = self.transform(normalized_data)\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "            return normalized_data, label\n",
        "        else:\n",
        "            return normalized_data\n",
        "\n"
      ],
      "metadata": {
        "id": "BzpAQUBBx3jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaders(file_paths, labels, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, batch_size=16):\n",
        "    dataset_size = len(file_paths)\n",
        "    train_size = int(train_ratio * dataset_size)\n",
        "    val_size = int(val_ratio * dataset_size)\n",
        "    test_size = dataset_size - train_size - val_size\n",
        "\n",
        "    dataset = HeartSoundDataset(file_paths, labels)\n",
        "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "UAhLBalsyYFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heart Sound Classifier"
      ],
      "metadata": {
        "id": "zl_1HYalyBFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HeartSoundClassifier(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(HeartSoundClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 8, kernel_size=5, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(8, 16, kernel_size=5, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(input_size // 4 * 16, 32)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-t4fWpCFx99a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training, Validation, Testing"
      ],
      "metadata": {
        "id": "ru7SmQPFzG32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data and create data loaders\n",
        "data_dir = ''\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "for label in os.listdir(data_dir):\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    for file_name in os.listdir(label_dir):\n",
        "        file_paths.append(os.path.join(label_dir, file_name))\n",
        "        labels.append(label)\n",
        "\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "train_loader, val_loader, test_loader = create_dataloaders(file_paths, encoded_labels)\n"
      ],
      "metadata": {
        "id": "z4RSLt6Yyk5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = len(train_loader.dataset[0][0])\n",
        "num_classes = len(np.unique(encoded_labels))\n",
        "model = HeartSoundClassifier(input_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "P_UyDLT0y0Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and validate the model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Train and validate the model\n",
        "num_epochs = 10\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Compute training accuracy and loss\n",
        "    train_acc = 100 * correct / total\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, labels in val_loader:\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Compute validation accuracy and loss\n",
        "    val_acc = 100 * correct / total\n",
        "    val_loss /= len(val_loader)\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.2f}%, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%')\n",
        "\n",
        "# Plot the loss functions\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zWha7uYly65X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for data, labels in test_loader:\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        y_true.extend(labels.numpy())\n",
        "        y_pred.extend(predicted.numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "V7lf_N-uy-zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt='d', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2f0eOplQzA3I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}